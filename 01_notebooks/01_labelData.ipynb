{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af343c1a",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "To use previously fine-tuned pretrained RoBERTa models to infer the polarity and aspect of ICLR sentences and then to aggregate these up as sentence frequencies describing the full review. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ab2ea",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aefd7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.conda/envs/n/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import random\n",
    "import glob\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import stanza\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2678f613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb234bb7",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26a09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 21:45:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 48.1MB/s]                    \n",
      "2024-05-11 21:45:49 INFO: Downloaded file to /home/jupyter/stanza_resources/resources.json\n",
      "2024-05-11 21:45:49 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-05-11 21:45:49 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "========================\n",
      "\n",
      "2024-05-11 21:45:49 INFO: Using device: cuda\n",
      "2024-05-11 21:45:49 INFO: Loading: tokenize\n",
      "2024-05-11 21:45:49 INFO: Loading: mwt\n",
      "2024-05-11 21:45:49 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "SENTENCIZE_PIPELINE = stanza.Pipeline(\"en\", processors=\"tokenize\")\n",
    "Sentence = collections.namedtuple(\"Sentence\", \"interval text\")\n",
    "TOKENIZER = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "SEED = 1\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986ee522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T19:10:27.573104Z",
     "iopub.status.busy": "2024-01-24T19:10:27.572692Z",
     "iopub.status.idle": "2024-01-24T19:10:27.578279Z",
     "shell.execute_reply": "2024-01-24T19:10:27.577228Z",
     "shell.execute_reply.started": "2024-01-24T19:10:27.573078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = os.path.dirname(os.getcwd()) + \"/\"\n",
    "INT = DIR + \"00_rawData/\"\n",
    "OUT = DIR + \"03_labeledData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06bf0434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/sandbox/valsInICLR/03_labeledData/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f25de",
   "metadata": {},
   "source": [
    "# Preprocessing and Prediction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab73f137",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dccd8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2018     2784\n",
       "2019     4332\n",
       "2020     6721\n",
       "2021    10022\n",
       "2022    10210\n",
       "2023    14359\n",
       "2024    28028\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr = pd.read_feather(INT+\"iclr_2018_2024.feather\")\n",
    "iclr['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2343f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'forum', 'reviewer', 'reviewer_id', 'review', 'rating',\n",
       "       'decision', 'len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07097d",
   "metadata": {},
   "source": [
    "# Process Raw Data\n",
    "Tokenize reviews into sentences, rendor as encoded tensors, and save as torch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf56404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chop_into_sentences(text):\n",
    "    doc = SENTENCIZE_PIPELINE(text)\n",
    "    sentences = []\n",
    "    for sentence in doc.sentences:\n",
    "        try:\n",
    "            sentence_dict = sentence.to_dict()\n",
    "            start = sentence_dict[0][\"start_char\"]\n",
    "            end = sentence_dict[-1][\"end_char\"]\n",
    "            sentences.append(Sentence((start, end), sentence.text))\n",
    "        except Exception as e:\n",
    "            # Uncomment to debug issues/errors:\n",
    "            # print(f\"Error tokenizing: {sentence.text}. Error: {e}\")\n",
    "            # print(sentence.text)\n",
    "            pass\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def tokenize_iclr_reviews(input_path):\n",
    "    \"\"\"\n",
    "    Uses spacy's sentence pipeline to tokenize reviews\n",
    "    into sentences. Returns df where row is review sentence\n",
    "    \"\"\"\n",
    "    output_path = input_path.replace(\".feather\", \"_sents.jsonl\")\n",
    "    reviews = pd.read_feather(input_path)\n",
    "    with open(output_path, 'w') as out_f:\n",
    "        for _, review in tqdm(reviews.iterrows(), total=reviews.shape[0], desc=\"Tokenizing Reviews\"):\n",
    "            review_sentences = _chop_into_sentences(review['review'])\n",
    "            for i, sentence in enumerate(review_sentences):\n",
    "                new_line = {\n",
    "                    \"ms_id\": review['forum'],\n",
    "                    \"Reviewer_ID\": review['reviewer_id'], \n",
    "                    \"identifier\": f\"{review['reviewer_id']}|||{i}\",\n",
    "                    \"sentence\": f\"{sentence.text}\",\n",
    "                }\n",
    "                out_f.write(json.dumps(new_line)+\"\\n\")\n",
    "\n",
    "                    \n",
    "def _process_batch(df):\n",
    "    \"\"\"\n",
    "    Helper; creates encodings for a batched df.\n",
    "    \"\"\"\n",
    "    df['text'] = df['sentence']\n",
    "    text_list = list(df['text'])\n",
    "\n",
    "    encodings = {'input_ids': [], 'attention_mask': [], 'identifier': list(df['identifier'])}\n",
    "    for text in text_list:\n",
    "        encoded = TOKENIZER(\n",
    "            text, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=128\n",
    "        )\n",
    "        encodings['input_ids'].append(encoded['input_ids'])\n",
    "        encodings['attention_mask'].append(encoded['attention_mask'])\n",
    "\n",
    "    return encodings\n",
    "\n",
    "\n",
    "def _worker(input_path, output_path, TOKENIZER, chunksize):\n",
    "    \"\"\"\n",
    "    A bit convoluted. But it helps speed up encoding by \n",
    "    parallel processing using all CPUs.\n",
    "    \"\"\"\n",
    "    reader = pd.read_json(input_path, orient=\"records\", lines=True, chunksize=chunksize)\n",
    "    all_encodings = {'input_ids': [], 'attention_mask': [], 'identifier': []}\n",
    "    progress = tqdm(total=2225000)  # hard coded to be n sentences in ICLR\n",
    "    with mp.Pool(mp.cpu_count()) as pool:  # backend CPU parallelization\n",
    "        for encodings in pool.imap(_process_batch, [df for df in reader]):\n",
    "            all_encodings['input_ids'].extend(encodings['input_ids'])\n",
    "            all_encodings['attention_mask'].extend(encodings['attention_mask'])\n",
    "            all_encodings['identifier'].extend(encodings['identifier'])\n",
    "            progress.update(chunksize)\n",
    "    progress.close()\n",
    "    pd.DataFrame(all_encodings).to_feather(output_path)\n",
    "\n",
    "        \n",
    "def encode_iclr_sents(input_path, tokenizer, chunksize=5000):\n",
    "    \"\"\"\n",
    "    `main` logic.\n",
    "    \"\"\"\n",
    "    output_path = input_path.replace(\"sents.jsonl\", \"encodings.feather\")\n",
    "    _worker(input_path, output_path, TOKENIZER, chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a88e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Reviews: 100%|██████████| 76456/76456 [47:29<00:00, 26.83it/s]  \n"
     ]
    }
   ],
   "source": [
    "# tokenize_iclr_reviews(input_path=INT+\"iclr_2018_2024.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98155ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2225000/2401686 [01:42<00:08, 21754.55it/s]\n"
     ]
    }
   ],
   "source": [
    "encode_iclr_sents(input_path=INT+\"iclr_2018_2024_sents.jsonl\", tokenizer=TOKENIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca188310",
   "metadata": {},
   "source": [
    "# Predict Sentence Labels\n",
    "For each task (\"variable\"), call in respective fine-tuned RoBERTa model and predict and write sentence labels to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "204ec775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model(model_dir):\n",
    "    \"\"\"\n",
    "    Gets fine-tuned RoBERTa model\n",
    "    \"\"\"\n",
    "    print(\"Loading trained model...\")\n",
    "     # Load the model configuration and create an instance\n",
    "    config = RobertaConfig.from_pretrained(model_dir)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_dir, config=config)\n",
    "    return model \n",
    "\n",
    "\n",
    "def _write_predictions_to_file(model, loader, variable, output_path):\n",
    "    \"\"\"\n",
    "    Predicts labels in batches and writes them to csv batch-wise\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\") as f, torch.cuda.amp.autocast():\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"identifier\", f\"{variable}_hat\"])\n",
    "        for i, batch in enumerate(tqdm(loader)):\n",
    "            inputs = {k: v.to(model.device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "            outputs = model(**inputs)\n",
    "            predictions = outputs.logits.argmax(axis=-1).detach().cpu().numpy()\n",
    "            identifiers = batch['identifier']\n",
    "            for identifier, prediction in zip(identifiers, predictions):\n",
    "                writer.writerow([identifier, prediction])\n",
    "   \n",
    "    \n",
    "def predict_iclr_sentence_labels(input_path, model_dir, variable):\n",
    "    \"\"\"\n",
    "    `main` fucntion\n",
    "    \"\"\"\n",
    "    output_path = input_path.replace(\"_encodings.feather\", f\"_{variable}_predictions.csv\")\n",
    "        \n",
    "    # use GPU\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = _load_model(model_dir).to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # load torch dataset\n",
    "    dataset = pd.read_feather(input_path)\n",
    "    dataset.to_dict(orient='list')\n",
    "    dataset = Dataset.from_dict(dataset)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'identifier'])\n",
    "    \n",
    "    # predict + write\n",
    "    with torch.no_grad():\n",
    "        loader = DataLoader(dataset, batch_size=64, num_workers=8, pin_memory=True)\n",
    "        print(f\"Predicting {variable}...\")\n",
    "        _write_predictions_to_file(model, loader, variable, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adef5ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "Predicting value...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34713/34713 [21:20<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "Predicting polarity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34713/34713 [21:22<00:00, 27.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# {'task': model_prefix}\n",
    "# we'll use the task to get the right model dir\n",
    "# we'll use the prefix to get the best preforming model\n",
    "model_map = {\n",
    "    \"value\": 8000, # prefix ~ n examples trained on\n",
    "    \"polarity\": 16000,\n",
    "}\n",
    "torch.set_grad_enabled(False)\n",
    "for variable, prefix in model_map.items():\n",
    "    model_dir = glob.glob(f\"/home/jupyter/01_predictions/judgments/{variable}/n_{prefix}*\")[0]\n",
    "    predict_iclr_sentence_labels(INT+\"iclr_2018_2024_encodings.feather\", model_dir, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395a351",
   "metadata": {},
   "source": [
    "# Aggregate\n",
    "Take disparate csvs with sentence-level predictions, combine them on the sentence level (aspect + polarity), then aggregate up to review level as sentence frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a488828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_labels():\n",
    "    label_map = {\n",
    "        \"polarity\": {\n",
    "            0: \"None\",\n",
    "            1: \"(+)\",\n",
    "            2: \"(–)\",\n",
    "        },\n",
    "        \"value\": {\n",
    "            0: \"None\",\n",
    "            1: \"Clarity\", # \"clr\",\n",
    "            2: \"Consistency\", # \"mng\",\n",
    "            3: \"Novelty\", # \"org\",\n",
    "            4: \"Thoroughness\", # \"subs\",\n",
    "            5: \"Accuracy\", # \"snd\",\n",
    "            6: \"Replicability\", # \"rep\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    predictions_dct = {}\n",
    "    for variable in \"polarity value\".split():\n",
    "        predictions_dct[variable] = pd.read_csv(INT+f\"iclr_2018_2024_{variable}_predictions.csv\")\n",
    "        predictions_dct[variable][f\"{variable}_hat\"] = predictions_dct[variable][f\"{variable}_hat\"].apply(lambda prediction: label_map[variable][prediction])\n",
    "        predictions_dct[variable].drop_duplicates(subset=\"identifier\", inplace=True)\n",
    "        \n",
    "        \n",
    "    # merge two variables into one df on identifier\n",
    "    predicitions_df = predictions_dct['value'].merge(predictions_dct['polarity'],                                                  \n",
    "                                                     how=\"left\", \n",
    "                                                     left_on=\"identifier\", \n",
    "                                                     right_on=\"identifier\", \n",
    "                                                     validate=\"one_to_one\")\n",
    "\n",
    "    # impose no aspect when sentence is non-evaluative\n",
    "    predicitions_df['value_hat'] = np.where(predicitions_df['polarity_hat']==\"None\", \"None\", predicitions_df['value_hat'])\n",
    "    predicitions_df['polarity_hat'] = np.where(predicitions_df['value_hat']==\"None\", \"None\", predicitions_df['polarity_hat'])\n",
    "\n",
    "    # combine labels: \"Value (polarity)\"\n",
    "    predicitions_df['value_judgment'] = predicitions_df['value_hat'] + \" \" + predicitions_df['polarity_hat']\n",
    "\n",
    "    # get review id, the aggregate key\n",
    "    predicitions_df['reviewer_id'] = predicitions_df['identifier'].apply(lambda identifier: identifier.split(\"|||\")[0])\n",
    "    return predicitions_df\n",
    "\n",
    "\n",
    "def aggregate():\n",
    "    \"\"\"\n",
    "    Finally aggregates the review sentence-level predictions\n",
    "    into a review-wise frequency array of value judgments. \n",
    "    \"\"\"\n",
    "   \n",
    "    df = _combine_labels()\n",
    "    output_path = OUT+\"iclr_2018_2024_labeled.jsonl\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for review_id, review_df in df.groupby(\"reviewer_id\"):\n",
    "            review_dct = review_df['value_judgment'].value_counts().to_dict()\n",
    "            review_dct[\"reviewer_id\"] = review_id\n",
    "            f.write(json.dumps(review_dct)+\"\\n\")\n",
    "\n",
    "    df = pd.read_json(output_path, orient=\"records\", lines=True)\n",
    "    df['ms_id'] = df['reviewer_id'].apply(lambda x: x.split(\"&&\")[0])\n",
    "    # na does not mean missing but no sents!\n",
    "    df = df.fillna(0)\n",
    "    cols = [col for col in df.columns if \"(\" in col]\n",
    "    print(df['ms_id'].nunique(),\"n manuscripts\", sep=\"\\t\")\n",
    "    print(df['reviewer_id'].nunique(), \"n reviews\", sep=\"\\t\")\n",
    "    print(pd.DataFrame(df[cols].describe()).T.round(2).sort_index())\n",
    "    print()\n",
    "    df.to_json(output_path, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b444c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20827\tn manuscripts\n",
      "76453\tn reviews\n",
      "                     count  mean   std  min  25%  50%  75%   max\n",
      "Accuracy (+)       76453.0  0.77  1.02  0.0  0.0  0.0  1.0   9.0\n",
      "Accuracy (–)       76453.0  2.50  2.50  0.0  1.0  2.0  4.0  34.0\n",
      "Clarity (+)        76453.0  0.64  0.86  0.0  0.0  0.0  1.0  12.0\n",
      "Clarity (–)        76453.0  2.14  2.89  0.0  0.0  1.0  3.0  48.0\n",
      "Consistency (+)    76453.0  0.17  0.44  0.0  0.0  0.0  0.0   5.0\n",
      "Consistency (–)    76453.0  0.88  1.29  0.0  0.0  0.0  1.0  19.0\n",
      "Novelty (+)        76453.0  1.57  1.60  0.0  0.0  1.0  2.0  14.0\n",
      "Novelty (–)        76453.0  1.26  1.55  0.0  0.0  1.0  2.0  17.0\n",
      "Replicability (+)  76453.0  0.08  0.31  0.0  0.0  0.0  0.0   7.0\n",
      "Replicability (–)  76453.0  0.40  0.82  0.0  0.0  0.0  1.0  15.0\n",
      "Thoroughness (+)   76453.0  0.68  0.92  0.0  0.0  0.0  1.0  11.0\n",
      "Thoroughness (–)   76453.0  3.50  3.06  0.0  1.0  3.0  5.0  51.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db2febb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr_labeled = pd.read_json(OUT+\"iclr_2018_2024_labeled.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc06c3",
   "metadata": {},
   "source": [
    "# Merge Labels with Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "392b283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr = iclr.drop_duplicates('reviewer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "221f6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr_labeled = iclr_labeled.merge(iclr, how=\"left\", on=[\"reviewer_id\"], validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eced234",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [col for col in iclr_labeled if \"(\" in col or \"None\" in col]\n",
    "old_cols = list(iclr.columns)\n",
    "iclr_labeled = iclr_labeled[old_cols+labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f91182ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1e7hs05Km&&2\n",
      "48\n",
      "Update after feedback: I would like to thank the authors for huge work done on improving the paper. I appreciate the tight time constrains given during the discussion phase and big steps towards more clear paper, but at the current stage I keep my opinion that the paper is not ready for publication. Also variability of concerns raised by other reviewers does not motivate acceptance.\n",
      "\n",
      "I would like to encourage the authors to make careful revision and I would be happy to see this work published. It looks very promising. \n",
      "\n",
      "Just an example of still unclear parts of the paper: the text between eq. (3) and (4). This describes the proposed method, together with theoretical discussions this is the main part of the paper. As a reader I would appreciate this part being written detailed, step by step.\n",
      "=========================================================\n",
      "\n",
      "The paper proposes the Bayesian version of DQN (by replacing the last layer with Bayesian linear regression) for efficient exploration. \n",
      "\n",
      "The paper looks very promising because of a relatively simple methodology (in the positive sense) and impressive results, but I find the paper having big issues with clarity. There are so many mistakes, typos, unclear statements and a questionable structure in the text that it is difficult to understand many parts. In the current version the paper is not ready for publication. \n",
      "\n",
      "In details (more in the order of appearance rather than of importance):\n",
      "1. It seems that the authors use “sample” for tuples from the experience replay buffer and draws W from its posterior distribution (at least for these two purposes), which is extremely confusing\n",
      "2. pp.1-2 “We show that the Bayesian regret is bounded by O(d \\sqrt{N}), after N time steps for a d-dimensional feature map, and this bound is shown to be tight up-to logarithmic factors.” – maybe too many details for an abstract and introduction and it is unclear for a reader anyway at that point\n",
      "3. p.1 “A central challenge in reinforcement learning (RL) is to design efficient exploration-exploitation tradeoff” – sounds too strong. Isn’t the central challenge to train an agent to get a maximum reward? It’s better to change to at least “One of central challenges”\n",
      "4. p.1 “ε-greedy which uniformly explores over all the non-greedy strategies with 1 − ε probability” – it is possible, but isn’t it more conventional for an epsilon-greedy policy to take a random action with the probability epsilon and acts greedy with the probability 1 – epsilon? Moreover, later in Section 2 the authors state the opposite “where with ε probability it chooses a random action and with 1 − ε probability it chooses the greedy action based on the estimated Q function.”\n",
      "5. p.1 “An action is chosen from the posterior distribution of the belief” – a posterior distribution is the belief\n",
      "6. p.2 “and follow the same target objective” – if BDQN is truly Bayesian it should find a posterior distribution over weights, whereas in DDQN there is no such concept as a posterior distribution over weights, therefore, this statement does not sound right\n",
      "7. p.2 “This can be considered as a surrogate for sample complexity and regret. Indeed, no single measure of performance provides a complete picture of an algorithm, and we present detailed experiments in Section 4” – maybe too many details for introduction (plus missing full stop at the end)\n",
      "8. p.2 “This is the cost of inverting a 512 × 512 matrix every 100,000 time steps, which is negligible.” – doesn’t this depend on some parameter choices? Now the claim looks like it is true unconditionally. Also too many details for introduction\n",
      "9. p.2 “On the other hand, more sophisticated Bayesian RL techniques are significantly more expensive and have not lead to large gains over DQN and DDQN.” – it would be better to justify the claim with some reference\n",
      "10. Previous work presented in Introduction is a bit confusing. If the authors want to focus only on Thompson Sampling approaches, then it is unclear, why they mentioned OFU methods. If they mention OFU methods, then it is unclear why other exploration methods are not covered (in Introduction). It is better to either move OFU methods to Related Work completely, or to give a taste of other methods (for example, from Related Work) in Introduction as well\n",
      "11. p.3 “Consider an MDP M as a tuple <X , A, P, P0, R, γ>, with state space X , action space A, the transition kernel P, accompanied with reward function of R, and discount factor 0 ≤ γ < 1.” – P_0 is not defined\n",
      "12. p.4 “A common assumption in DNN is that the feature representation is suitable for linear classification or regression (same assumption in DDQN), therefore, building a linear model on the features is a suitable choice.” – the statement is more confusing than explaining. Maybe it is better to state that the last fully connected layer, representing linear relationship, in DQN is replaced with BLR in the proposed model\n",
      "13. p.5 In eq. (3) it is better to carry definition of $\\bar{w}_a$ outside the Gaussian distribution, as it is done for $\\Xi_a$\n",
      "14. p.5 The text between eq. (3) and (4) seems to be important for the model description and yet it is very unclear: how $a_{TS}$ is used? “we draw $w_a$ follow $a_{TS}$” – do the authors mean “following” (though it is still unclear with “following”)? What does notation $[W^T \\phi^{\\theta} (x_{\\tau})]_{a_{\\tau}}$ denote? Which time steps do the authors mean?\n",
      "15. p.5 The paragraph under eq. (4) is also very confusing. “to the mean of the posterior A.6.” – reference to the appendix without proper verbal reference. Cov in Algorithm 1 is undefined, is it equal to $\\Xi$? Notation in step 8 in Algorithm 1 is too complicated.\n",
      "16. Algorithm 1 gives a vague idea about the proposed algorithm, but the text should be revised, the current version is very unclear and confusing\n",
      "17. pp.5-6 The text of the authors' attempts to reproduce the results of others' work (from \"We also aimed to implement...\" to \"during the course of learning and exploration\") should be formalised\n",
      "18. p. 6 \"We report the number of samples\" - which samples? W? from the buffer replay?\n",
      "19. p. 6 missing reference for DDQN+\n",
      "20. p. 6 definition of SC+ and references for baselines should be moved from the table caption to the main text of the paper\n",
      "21. p. 6 Table 3 is never discussed, appears in a random place of the text, there should be note in its reference that it is in the appendix\n",
      "22. p.6 Where is the text for footnotes 3-6?\n",
      "23. p.6 Table 2 may be transposed to fit the borders\n",
      "24. p.6 (and later) It is unclear why exploration in BDQN is called targeted\n",
      "25. p.7 Caption of Figure 3 is not very good\n",
      "26. p.7 Too small font size of axis labels and titles in plots in Figure 3 (there is still a room for 1.5 pages, moreover the paper is allowed to go beyond 10 pages due to big figures)\n",
      "27. p.7 Figure 3. Why Assault has different from the others y-axis? Why in y-axis (for the others) is \"per episode\" and x-axis is \"number of steps\" (wise versa for Assault)?\n",
      "27. Section 5 should go before Experiments\n",
      "28. p. 7 “Where Ψ is upper triangular matrix all ones 6.” – reference 6 should be surrounded by brackets and/or preceded by \"eq.\" and it is unclear what “all ones” means especially given than the matrix in eq. (6) does not contain only ones\n",
      "29. p. 7 “Similar to the linear bandit problems,” – missing citation\n",
      "30. p. 7 PSRL appears in the theorem, but is introduced only later in Related work\n",
      "31. p. 7 “Proof: in Theorem. B” – proof is given in Appendix B?\n",
      "32. p. 8 Theorem discussion, “grows not faster than linear in the dimension, and \\sqrt(HT)” – unclear. Is it linear in the product of dimension (of what?) and \\sqrt(HT)?\n",
      "33. p.8 “On lower bound; since for H = 1…” – what on lower bound?\n",
      "34. p.8 “our bound is order optimal in d and T” – what do the authors mean by this?\n",
      "35. p.8 \"while also the state of the art performance bounds are preserved\" - what does it mean?\n",
      "36. p.8 \"To combat these shortcomings, \" - which ones?\n",
      "37. p.8 \"one is common with our set of 15 games which BDQN outperformS it...\" - what is it?\n",
      "38. p.9 \"Due to the computational limitations...\" - it is better to remove this sentence\n",
      "39. p.9 missing connection in \"where the feature representation is fixed, BDQN is given the feature representation\", or some parts of this sentence should be removed?\n",
      "40. p.9 PAC is not introduced\n",
      "41. pp.13-14 There is no need to divide Appendices A.2 and A.3. In fact, it is more confusing than helpful with the last paragraph in A.2 repeating, sometimes verbatim, the beginning of the first paragraph in A.3\n",
      "42. In the experiments, do the authors pre-train their BDQN with DQN? In this case, it is unfair to say that BDQN learns faster than DDQN if the latter is not pre-trained with DQN as well. Or is pre-training with DQN is used only for hyperparameter tuning?\n",
      "43. p.14 “Fig. 4 shows that the DDQN with higher learning rates learns as good as BDQN at the very beginning but it can not maintain the rate of improvement and degrade even worse than the original DDQN.” – it seems that the authors tried two learning rates for DDQN, for the one it is clear that it is set to 0.0025, another one is unclear. The word “original” is also unclear in this context. From the legend of Figure 4 it seems that the second choice for the learning rate is 0.00025, but it should be stated in the text more explicitly. The legend label “DDQN-10xlr” is not the best choice either. It is better to specify explicitly the value of the learning rate for both DDQN\n",
      "44. p.15 “As it is mentioned in Alg. 1, to update the posterior distribution, BDQN draws B samples from the replay buffer and needs to compute the feature vector of them.” – B samples never mentioned in Algorithm 1\n",
      "45. p.15 “during the duration of 100k decision making steps, for the learning procedure,” – i) “during … duration”, ii) what did the authors meant by “decision making steps” and “the learning procedure”?, and iii) too many commas\n",
      "46. p.15 “where $\\tilde{T}^{sample}$, the period that of $\\tilde{W}$ is sampled our of posterior” – this text does not make sense. Is “our” supposed to be “out”? “… the number of steps, after which a new $\\tilde{W}$ is sampled from the posterior”?\n",
      "47. p.15 “$\\tilde{W}$ is being used just for making Thompson sampling actions” – could the authors be more specific about the actions here?\n",
      "48. p.16 “In BDQN, as mentioned in Eq. 3, the prior and likelihood are conjugate of each others.” – it is difficult to imagine that an equation would mention anything and eq. (3) gives just the final formula for the posterior, rather than the prior and likelihood\n",
      "49. p.16 The formula after “we have a closed form posterior distribution of the discounted return, ” is unclear\n",
      "50. p.17 “we use ω instead of ω to avoid any possible confusion” – are there any differences between two omegas?\n",
      "51. p.17 what is $\\hat{b}_t$?\n",
      "\n",
      "There are a lot of minor mistakes and typos also, I will add them as a comment since there is a limit of characters for the review.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iclr_labeled.sort_values(by=\"Clarity (–)\", ascending=False)[\"reviewer_id\"].iloc[0])\n",
    "print(iclr_labeled.sort_values(by=\"Clarity (–)\", ascending=False)[\"Clarity (–)\"].iloc[0])\n",
    "print(iclr_labeled.sort_values(by=\"Clarity (–)\", ascending=False)['review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f20fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr_labeled.to_feather(OUT+\"iclr_labeled.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee0f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m65"
  },
  "kernelspec": {
   "display_name": "n",
   "language": "python",
   "name": "n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
